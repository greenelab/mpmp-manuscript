## Supplementary Information

A version of the main paper figures using the area under the receiver-operator curve (AUROC) metric rather than AUPR is available at [`https://doi.org/10.6084/m9.figshare.14919729`](https://doi.org/10.6084/m9.figshare.14919729).

In a previous version of this paper, we ran our analysis only for the genes in the Vogelstein et al. [@doi:10.1126/science.1235122] gene set. Scaling up the gene set, by combining cancer gene sets from the literature as described in the methods/results sections, affected the study results somewhat, as mutations in the added genes tend to be better predicted using gene expression than other data types. During the revision, we explored the difference between the genes in this gene set, and the genes in the "merged" gene set but not in the Vogelstein genes. GO analysis results for the Vogelstein genes are available at [`https://doi.org/10.6084/m9.figshare.19565890`](https://doi.org/10.6084/m9.figshare.19565890), and results for the non-Vogelstein genes are available at [`https://doi.org/10.6084/m9.figshare.19565887`](https://doi.org/10.6084/m9.figshare.19565887). In general, we noticed that the non-Vogelstein genes tend to be enriched for terms relating to transcription factors and transcriptional regulation.

As a data resource, coefficients and hyperparameter choices for final models fit using gene expression features are available on Figshare: coefficients are available at [`https://doi.org/10.6084/m9.figshare.19576012`](https://doi.org/10.6084/m9.figshare.19576012) and hyperparameters are at [`https://doi.org/10.6084/m9.figshare.19576048`](https://doi.org/10.6084/m9.figshare.19576048). Columns in the coefficients dataset correspond to target genes (gene symbols), and rows correspond either to gene expression features (Entrez IDs) or covariates (cancer type indicator variables or log(mutation burden)). An 'NA' value in a cell indicates that feature was not used in the model for the corresponding gene (for a gene feature this means that gene was not in the top 8000 genes by MAD, for a cancer type feature this means that cancer type was not included in the training set based on our mutation filters). A 0 value in a cell indicates that feature was included in model training, but it was not selected by the elastic net feature selection algorithm. Columns in the hyperparameters dataset correspond to hyperparameters (alpha and l1_ratio for elastic net logistic regression) and rows correspond to target genes.

Regarding the hyperparameters for the final models, recall that for the main figures in the paper, we evaluate each of our models using 2 replicates of 4-fold cross-validation. For each of these folds (train/test splits), we further split the training set into train and validation sets to select hyperparameters, independently for each fold, and evaluate the models on the test set to get the results in the paper. Because we are evaluating performance over multiple folds, it is not perfectly straightforward to get a single set of regression coefficients, since we have a (potentially different) set of coefficients for each cross-validation fold. In order to synthesize these results into a single model for each gene in each data type, we selected one of the 8 sets of hyperparameters (from the 8 best models, 1 per CV fold) at random, with probability proportional to performance (AUPR) on the validation set used to select the hyperparameters, described above (so test set performance is not used here). We then used the selected hyperparameters to train a single model on the entire dataset.

![
Proportion of samples from each TCGA cancer type that are "dropped" as more data types are added to our analyses. We started with gene expression data, and for each added data type, we took the intersection of samples that were profiled for that data type and the previous data types, dropping all samples that were missing 1 or more data types. Overall, at each step, the proportions of "dropped" samples appear to be fairly evenly spread between cancer types, showing that in general we are not disproportionately losing one or several cancer types as more data modalities are added to our analyses.
](images/supp_figure_8.png){#fig:cancer_type_proportions width=80%}

| cancer type | mutation | me_27k | me_450k | mut_sigs | mirna | rppa | base |
|-------------|----------|--------|---------|----------|-------|------|------|
| ACC | 3 | 0 | 0 | 0 | 0 | 32 | 44 |
| BLCA | 29 | 0 | 0 | 20 | 3 | 65 | 310 |
| BRCA | 237 | 16 | 291 | 44 | 9 | 109 | 512 |
| CESC | 38 | 0 | 0 | 18 | 0 | 120 | 134 |
| CHOL | 9 | 0 | 3 | 0 | 0 | 6 | 27 |
| COAD | 154 | 0 | 77 | 15 | 0 | 33 | 216 |
| DLBC | 11 | 0 | 0 | 6 | 0 | 10 | 21 |
| ESCA | 27 | 0 | 0 | 0 | 0 | 53 | 116 |
| GBM | 48 | 0 | 73 | 12 | 39 | 0 | 0 |
| HNSC | 79 | 0 | 0 | 39 | 3 | 267 | 178 |
| KICH | 26 | 0 | 0 | 15 | 0 | 2 | 48 |
| KIRC | 254 | 0 | 97 | 16 | 0 | 18 | 221 |
| KIRP | 52 | 0 | 13 | 17 | 0 | 53 | 188 |
| LAML | 58 | 1 | 0 | 0 | 0 | 114 | 0 |
| LGG | 23 | 0 | 1 | 8 | 4 | 85 | 409 |
| LIHC | 75 | 0 | 1 | 46 | 2 | 179 | 120 |
| LUAD | 74 | 1 | 56 | 20 | 1 | 125 | 299 |
| LUSC | 89 | 1 | 113 | 21 | 4 | 94 | 231 |
| MESO | 5 | 0 | 0 | 0 | 0 | 23 | 59 |
| OV | 132 | 2 | 166 | 0 | 0 | 0 | 8 |
| PAAD | 31 | 0 | 2 | 2 | 0 | 51 | 97 |
| PCPG | 26 | 0 | 0 | 1 | 0 | 83 | 77 |
| PRAD | 71 | 0 | 0 | 10 | 4 | 134 | 331 |
| READ | 53 | 0 | 29 | 1 | 0 | 20 | 68 |
| SARC | 36 | 0 | 0 | 28 | 1 | 33 | 167 |
| SKCM | 111 | 0 | 0 | 52 | 14 | 92 | 205 |
| STAD | 67 | 0 | 40 | 25 | 0 | 67 | 251 |
| TGCT | 12 | 0 | 0 | 0 | 0 | 30 | 114 |
| THCA | 92 | 0 | 1 | 16 | 1 | 124 | 338 |
| THYM | 3 | 0 | 0 | 0 | 0 | 32 | 87 |
| UCEC | 60 | 0 | 109 | 22 | 0 | 84 | 292 |
| UCS | 1 | 0 | 0 | 0 | 1 | 9 | 46 |
| UVM | 0 | 0 | 0 | 0 | 0 | 68 | 12 |

Table: Number of samples from each TCGA cancer type that are "dropped" as more data types are added to the analysis. The "base" column indicates the number of samples that are present per cancer type in the final intersection of all data types (i.e. each sample counted in the last column has data for each of the 7 data types, including gene expression (not listed here) and somatic mutations). {#tbl:cancer_type_proportions}

![
Heatmap displaying predictive performance for mutations in each of the 84 genes from the Vogelstein et al. gene set, across gene expression and the two DNA methylation arrays. Each cell quantifies performance for a target gene, using predictive features derived from a particular data type. Grey shaded dots indicate that the given data type provides significantly better predictions than the permuted baseline for the given gene; black inner dots indicate the same and additionally that the given data type provides statistically equivalent performance to the data type with the best average performance (determined by pairwise _t_-tests across data types with FDR correction).
](images/supp_figure_9.png){#fig:methylation_heatmap width=90%}

![
Volcano-like plots showing predictive performance for each gene in the Vogelstein et al. gene set for expression and DNA methylation, on the sample set used for the "all data types" experiments. The first row shows performance relative to the permuted baseline, and the second row shows direct comparisons between data types. The _x_-axis shows the difference in mean AUPR compared with a baseline model trained on permuted labels, and the _y_-axis shows _p_-values for a paired _t_-test comparing cross-validated AUPR values within folds.
](images/supp_figure_10.png){#fig:all_volcano_me width=90%}

![
Volcano-like plots showing predictive performance for each gene in the Vogelstein et al. gene set for all data types, relative to the permuted baseline model, when genes are filtered based on the entire dataset rather than by cancer type.
For this filtering approach, we included/excluded entire genes rather than individual cancer types: specifically, we trained a classifier for each gene where all cancer types combined had at least 5% mutated samples and at least 100 total mutated samples, resulting in 182 total classifiers.
The _x_-axis shows the difference in mean AUPR compared with a baseline model trained on permuted labels, and the _y_-axis shows _p_-values for a paired _t_-test comparing cross-validated AUPR values within folds.
Counts of genes making the significance threshold of 0.001: gene expression 81/182 (44.5%), 27K methylation 16/182 (8.8%), 450K methylation 1/182 (0.6%), RPPA 41/182 (22.5%), microRNA 25/182 (13.7%), mutational signatures 7/182 (3.9%).
](images/supp_figure_11.png){#fig:all_volcano_filter width=90%}

![
Predictive performance for genes in the Vogelstein et al. gene set, using each of the three data types as predictors.
The _x_-axis shows the number of PCA components used as features, "raw" = no PCA compression.
](images/supp_figure_12.png){#fig:me_compress_boxes width=90%}

![
Top plot: comparing the best-performing model (i.e. highest mean AUPR relative to permuted baseline) trained on a single data type against the best "multi-omics" model for each target gene, using raw (not PCA compressed) features. For feature parity between data types, the top 20,000 features by mean absolute deviation were used for each data type.
The difference between single-omics and multi-omics performance for _TP53_ was statistically significant (_p_=0.0078), but other differences between single-omics and multi-omics models were not statistically significant using paired-sample Wilcoxon tests across cross-validation folds, for a threshold of 0.05.
Bottom plots: classifier performance, relative to baseline with permuted labels, for individual genes. Each panel shows performance for one of the six target genes; box plots show performance distribution over 8 evaluation sets (4 cross-validation folds x 2 replicates).
](images/supp_figure_13.png){#fig:multi_omics_raw_feats width=90%}

![
Top plot: comparing the best-performing model (i.e. highest mean AUPR relative to permuted baseline) trained on a single data type against the best "multi-omics" model for each target gene, using a 3-layer fully-connected neural network. The top 5,000 principal components were used as predictive features for each data type.
The difference between single-omics and multi-omics performance for _PIK3CA_ (_p_ = 0.0156, in favor of multi-omics) and _TP53_ (_p_ = 0.0391, in favor of single-omics) were statistically significant, but other differences between single-omics and multi-omics models were not statistically significant using paired-sample Wilcoxon tests across cross-validation folds, for a threshold of 0.05.
Bottom plots: comparison of classifier performance between elastic net and fully-connected NN, relative to baseline with permuted labels, for individual genes. Each panel shows performance for one of the six target genes; box plots show performance distribution over 8 evaluation sets (4 cross-validation folds x 2 replicates).
](images/supp_figure_14.png){#fig:multi_omics_mlp width=90%}
